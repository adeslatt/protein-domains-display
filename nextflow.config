// Enable DSL2
nextflow.enable.dsl=2

profiles {
    standard {
        process {
            executor = 'local'       // Run locally
            conda = "environment.yml" // Ensures all processes use Conda environment
            cpus = 4                 // Default CPUs per process
            memory = '8GB'           // Default memory per process
            time = '2h'              // Max execution time per process
            errorStrategy = 'retry'  // Retry failed tasks before failing the pipeline
            maxRetries = 3           // Retry failed tasks up to 3 times
        }

        params {
            gff_dir = """${HOME}/Dropbox (Personal)/Scitechcon Dropbox/projects/protein-domains-display/data/protein_domain_coordinates"""
            counts_dir = """${HOME}/Dropbox (Personal)/Scitechcon Dropbox/projects/protein-matrices"""
            output_dir = """${HOME}/Dropbox (Personal)/Scitechcon Dropbox/projects/protein-domains-display/output"""
            chrom_sizes = """${HOME}/Dropbox (Personal)/Scitechcon Dropbox/projects/protein-domains-display/data/hg38.chrom.sizes"""
        }

        trace {
            overwrite = true         // Allows overwriting trace files
        }

        report {
            overwrite = true         // Allows overwriting report files
            enabled = true
            file = "output/nextflow_report.html"
        }

        dag {
            overwrite = true         // Allows overwriting dag files
            enabled = true
            file = "output/workflow_dag.png"
        }

        timeline {
            overwrite = true         // Allows overwriting timeline files
            enabled = true
            file = "output/nextflow_timeline.html"
        }
    }

    cloud {
        process {
            executor = 'awsbatch'    // Use AWS Batch for cloud execution
            queue = 'nextflow-job'   // AWS Batch job queue
            conda = "environment.yml" // Use Conda environment in cloud execution
            cpus = 8                 // Increase CPU per task for cloud
            memory = '16GB'          // Increase memory for cloud execution
            time = '4h'              // Increase time for cloud jobs
            errorStrategy = 'retry'  // Cloud execution should retry failed tasks
            maxRetries = 5           // Retry failed jobs up to 5 times
        }

        params {
            gff_dir = """s3://your-bucket/data/protein_domain_coordinates"""
            counts_dir = """s3://your-bucket/data/protein_matrices"""
            output_dir = """s3://your-bucket/output"""
            chrom_sizes = """s3://your-bucket/data/hg38.chrom.sizes"""
        }

        trace {
            overwrite = true         // Allows overwriting trace files
        }

        report {
            overwrite = true         // Allows overwriting report files
            enabled = true
            file = "output/nextflow_report.html"
        }

        dag {
            overwrite = true         // Allows overwriting dag files
            enabled = true
            file = "output/workflow_dag.png"
        }

        timeline {
            overwrite = true         // Allows overwriting timeline files
            enabled = true
            file = "output/nextflow_timeline.html"
        }
    }
}

